{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_my_CNN_model_architecture():\n",
    "    '''\n",
    "    The network should accept a 96x96 grayscale image as input, and it should output a vector with 30 entries,\n",
    "    corresponding to the predicted (horizontal and vertical) locations of 15 facial keypoints.\n",
    "    '''\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(32, (5, 5), input_shape=(96,96,1), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Convolution2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.1))\n",
    "\n",
    "    model.add(Convolution2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Convolution2D(30, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(30))\n",
    "\n",
    "    return model;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_my_CNN_model(model, optimizer, loss, metrics):\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "\n",
    "def train_my_CNN_model(model, X_train, y_train):\n",
    "    return model.fit(X_train, y_train, epochs=100, batch_size=200, verbose=1, validation_split=0.2)\n",
    "\n",
    "def save_my_CNN_model(model, fileName):\n",
    "    model.save(fileName + '.h5')\n",
    "\n",
    "def load_my_CNN_model(fileName):\n",
    "    return load_model(fileName + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Daman\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\Daman\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 1712 samples, validate on 428 samples\n",
      "Epoch 1/100\n",
      "1712/1712 [==============================] - 17s 10ms/step - loss: 0.1131 - acc: 0.5794 - val_loss: 0.0702 - val_acc: 0.6963\n",
      "Epoch 2/100\n",
      "1712/1712 [==============================] - 16s 9ms/step - loss: 0.0532 - acc: 0.7074 - val_loss: 0.0426 - val_acc: 0.6963\n",
      "Epoch 3/100\n",
      "1712/1712 [==============================] - 16s 9ms/step - loss: 0.0248 - acc: 0.7074 - val_loss: 0.0172 - val_acc: 0.6963\n",
      "Epoch 4/100\n",
      "1712/1712 [==============================] - 16s 10ms/step - loss: 0.0107 - acc: 0.7074 - val_loss: 0.0154 - val_acc: 0.6963\n",
      "Epoch 5/100\n",
      "1712/1712 [==============================] - 16s 9ms/step - loss: 0.0067 - acc: 0.6530 - val_loss: 0.0127 - val_acc: 0.6963\n",
      "Epoch 6/100\n",
      "1712/1712 [==============================] - 15s 9ms/step - loss: 0.0057 - acc: 0.6986 - val_loss: 0.0073 - val_acc: 0.6963\n",
      "Epoch 7/100\n",
      "1712/1712 [==============================] - 18s 10ms/step - loss: 0.0053 - acc: 0.7074 - val_loss: 0.0107 - val_acc: 0.6963\n",
      "Epoch 8/100\n",
      "1712/1712 [==============================] - 18s 11ms/step - loss: 0.0050 - acc: 0.7074 - val_loss: 0.0093 - val_acc: 0.6963\n",
      "Epoch 9/100\n",
      "1712/1712 [==============================] - 18s 11ms/step - loss: 0.0049 - acc: 0.7074 - val_loss: 0.0099 - val_acc: 0.6963\n",
      "Epoch 10/100\n",
      "1712/1712 [==============================] - 18s 10ms/step - loss: 0.0049 - acc: 0.7074 - val_loss: 0.0107 - val_acc: 0.6963\n",
      "Epoch 11/100\n",
      "1712/1712 [==============================] - 18s 11ms/step - loss: 0.0047 - acc: 0.7074 - val_loss: 0.0099 - val_acc: 0.6963\n",
      "Epoch 12/100\n",
      "1712/1712 [==============================] - 18s 10ms/step - loss: 0.0047 - acc: 0.7074 - val_loss: 0.0097 - val_acc: 0.6963\n",
      "Epoch 13/100\n",
      "1712/1712 [==============================] - 20s 12ms/step - loss: 0.0047 - acc: 0.7074 - val_loss: 0.0089 - val_acc: 0.6963\n",
      "Epoch 14/100\n",
      "1712/1712 [==============================] - 20s 12ms/step - loss: 0.0047 - acc: 0.7074 - val_loss: 0.0088 - val_acc: 0.6963\n",
      "Epoch 15/100\n",
      "1712/1712 [==============================] - 22s 13ms/step - loss: 0.0046 - acc: 0.7074 - val_loss: 0.0079 - val_acc: 0.6963\n",
      "Epoch 16/100\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 0.0046 - acc: 0.7074 - val_loss: 0.0090 - val_acc: 0.6963\n",
      "Epoch 17/100\n",
      "1712/1712 [==============================] - 20s 11ms/step - loss: 0.0046 - acc: 0.7074 - val_loss: 0.0077 - val_acc: 0.6963\n",
      "Epoch 18/100\n",
      "1712/1712 [==============================] - 18s 11ms/step - loss: 0.0045 - acc: 0.7074 - val_loss: 0.0076 - val_acc: 0.6963\n",
      "Epoch 19/100\n",
      "1712/1712 [==============================] - 18s 11ms/step - loss: 0.0046 - acc: 0.7074 - val_loss: 0.0081 - val_acc: 0.6963\n",
      "Epoch 20/100\n",
      "1712/1712 [==============================] - 18s 11ms/step - loss: 0.0045 - acc: 0.7074 - val_loss: 0.0068 - val_acc: 0.6963\n",
      "Epoch 21/100\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 0.0045 - acc: 0.7074 - val_loss: 0.0073 - val_acc: 0.6963\n",
      "Epoch 22/100\n",
      "1712/1712 [==============================] - 18s 11ms/step - loss: 0.0045 - acc: 0.7074 - val_loss: 0.0062 - val_acc: 0.6963\n",
      "Epoch 23/100\n",
      "1712/1712 [==============================] - 18s 11ms/step - loss: 0.0045 - acc: 0.7074 - val_loss: 0.0057 - val_acc: 0.6963\n",
      "Epoch 24/100\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 0.0045 - acc: 0.7074 - val_loss: 0.0061 - val_acc: 0.6963\n",
      "Epoch 25/100\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 0.0044 - acc: 0.7074 - val_loss: 0.0073 - val_acc: 0.6963\n",
      "Epoch 26/100\n",
      "1712/1712 [==============================] - 18s 11ms/step - loss: 0.0044 - acc: 0.7074 - val_loss: 0.0062 - val_acc: 0.6963\n",
      "Epoch 27/100\n",
      "1712/1712 [==============================] - 18s 11ms/step - loss: 0.0043 - acc: 0.7074 - val_loss: 0.0052 - val_acc: 0.6963\n",
      "Epoch 28/100\n",
      "1712/1712 [==============================] - 18s 10ms/step - loss: 0.0045 - acc: 0.7074 - val_loss: 0.0066 - val_acc: 0.6963\n",
      "Epoch 29/100\n",
      "1712/1712 [==============================] - 18s 11ms/step - loss: 0.0045 - acc: 0.7074 - val_loss: 0.0049 - val_acc: 0.6963\n",
      "Epoch 30/100\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 0.0045 - acc: 0.7074 - val_loss: 0.0064 - val_acc: 0.6963\n",
      "Epoch 31/100\n",
      "1712/1712 [==============================] - 20s 11ms/step - loss: 0.0044 - acc: 0.7074 - val_loss: 0.0061 - val_acc: 0.6963\n",
      "Epoch 32/100\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 0.0043 - acc: 0.7074 - val_loss: 0.0050 - val_acc: 0.6963\n",
      "Epoch 33/100\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 0.0042 - acc: 0.7074 - val_loss: 0.0050 - val_acc: 0.6963\n",
      "Epoch 34/100\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 0.0042 - acc: 0.7074 - val_loss: 0.0051 - val_acc: 0.6963\n",
      "Epoch 35/100\n",
      "1712/1712 [==============================] - 20s 11ms/step - loss: 0.0042 - acc: 0.7074 - val_loss: 0.0046 - val_acc: 0.6963\n",
      "Epoch 36/100\n",
      "1712/1712 [==============================] - 22s 13ms/step - loss: 0.0041 - acc: 0.7074 - val_loss: 0.0054 - val_acc: 0.6963\n",
      "Epoch 37/100\n",
      "1712/1712 [==============================] - 20s 11ms/step - loss: 0.0042 - acc: 0.7074 - val_loss: 0.0048 - val_acc: 0.6963\n",
      "Epoch 38/100\n",
      "1712/1712 [==============================] - 18s 11ms/step - loss: 0.0041 - acc: 0.7074 - val_loss: 0.0045 - val_acc: 0.6963\n",
      "Epoch 39/100\n",
      "1712/1712 [==============================] - 18s 11ms/step - loss: 0.0041 - acc: 0.7074 - val_loss: 0.0047 - val_acc: 0.6963\n",
      "Epoch 40/100\n",
      "1712/1712 [==============================] - 18s 11ms/step - loss: 0.0040 - acc: 0.7074 - val_loss: 0.0043 - val_acc: 0.6963\n",
      "Epoch 41/100\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 0.0040 - acc: 0.7074 - val_loss: 0.0054 - val_acc: 0.6963\n",
      "Epoch 42/100\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 0.0040 - acc: 0.7074 - val_loss: 0.0051 - val_acc: 0.6963\n",
      "Epoch 43/100\n",
      "1712/1712 [==============================] - 22s 13ms/step - loss: 0.0040 - acc: 0.7074 - val_loss: 0.0047 - val_acc: 0.6963\n",
      "Epoch 44/100\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 0.0039 - acc: 0.7074 - val_loss: 0.0047 - val_acc: 0.6963\n",
      "Epoch 45/100\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 0.0039 - acc: 0.7074 - val_loss: 0.0041 - val_acc: 0.6963\n",
      "Epoch 46/100\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 0.0039 - acc: 0.7074 - val_loss: 0.0041 - val_acc: 0.6963\n",
      "Epoch 47/100\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 0.0038 - acc: 0.7074 - val_loss: 0.0043 - val_acc: 0.6963\n",
      "Epoch 48/100\n",
      "1712/1712 [==============================] - 20s 11ms/step - loss: 0.0037 - acc: 0.7074 - val_loss: 0.0041 - val_acc: 0.6963\n",
      "Epoch 49/100\n",
      "1712/1712 [==============================] - 20s 12ms/step - loss: 0.0037 - acc: 0.7068 - val_loss: 0.0041 - val_acc: 0.6963\n",
      "Epoch 50/100\n",
      "1712/1712 [==============================] - 18s 11ms/step - loss: 0.0036 - acc: 0.7068 - val_loss: 0.0041 - val_acc: 0.6963\n",
      "Epoch 51/100\n",
      "1712/1712 [==============================] - 18s 11ms/step - loss: 0.0035 - acc: 0.7074 - val_loss: 0.0036 - val_acc: 0.6963\n",
      "Epoch 52/100\n",
      "1712/1712 [==============================] - 18s 11ms/step - loss: 0.0034 - acc: 0.7074 - val_loss: 0.0035 - val_acc: 0.6963\n",
      "Epoch 53/100\n",
      "1712/1712 [==============================] - 15s 9ms/step - loss: 0.0034 - acc: 0.7074 - val_loss: 0.0041 - val_acc: 0.6963\n",
      "Epoch 54/100\n",
      "1712/1712 [==============================] - 16s 10ms/step - loss: 0.0033 - acc: 0.7074 - val_loss: 0.0036 - val_acc: 0.6963\n",
      "Epoch 55/100\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 0.0032 - acc: 0.7074 - val_loss: 0.0032 - val_acc: 0.6963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/100\n",
      "1712/1712 [==============================] - 16s 9ms/step - loss: 0.0031 - acc: 0.7079 - val_loss: 0.0029 - val_acc: 0.6963\n",
      "Epoch 57/100\n",
      "1712/1712 [==============================] - 16s 9ms/step - loss: 0.0030 - acc: 0.7074 - val_loss: 0.0031 - val_acc: 0.6963\n",
      "Epoch 58/100\n",
      "1712/1712 [==============================] - 15s 9ms/step - loss: 0.0029 - acc: 0.7074 - val_loss: 0.0034 - val_acc: 0.6963\n",
      "Epoch 59/100\n",
      "1712/1712 [==============================] - 15s 9ms/step - loss: 0.0029 - acc: 0.7103 - val_loss: 0.0028 - val_acc: 0.6939\n",
      "Epoch 60/100\n",
      "1712/1712 [==============================] - 15s 9ms/step - loss: 0.0028 - acc: 0.7068 - val_loss: 0.0028 - val_acc: 0.6963\n",
      "Epoch 61/100\n",
      "1712/1712 [==============================] - 16s 10ms/step - loss: 0.0027 - acc: 0.7062 - val_loss: 0.0030 - val_acc: 0.7009\n",
      "Epoch 62/100\n",
      "1712/1712 [==============================] - 16s 9ms/step - loss: 0.0026 - acc: 0.7044 - val_loss: 0.0025 - val_acc: 0.7033\n",
      "Epoch 63/100\n",
      "1712/1712 [==============================] - 15s 9ms/step - loss: 0.0025 - acc: 0.7068 - val_loss: 0.0023 - val_acc: 0.7079\n",
      "Epoch 64/100\n",
      "1712/1712 [==============================] - 17s 10ms/step - loss: 0.0024 - acc: 0.7097 - val_loss: 0.0024 - val_acc: 0.7079\n",
      "Epoch 65/100\n",
      "1712/1712 [==============================] - 16s 9ms/step - loss: 0.0023 - acc: 0.7085 - val_loss: 0.0024 - val_acc: 0.7056\n",
      "Epoch 66/100\n",
      "1712/1712 [==============================] - 16s 9ms/step - loss: 0.0023 - acc: 0.7091 - val_loss: 0.0025 - val_acc: 0.7079\n",
      "Epoch 67/100\n",
      "1712/1712 [==============================] - 15s 9ms/step - loss: 0.0023 - acc: 0.7091 - val_loss: 0.0025 - val_acc: 0.7079\n",
      "Epoch 68/100\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 0.0022 - acc: 0.7079 - val_loss: 0.0021 - val_acc: 0.7079\n",
      "Epoch 69/100\n",
      "1712/1712 [==============================] - 21s 12ms/step - loss: 0.0021 - acc: 0.7155 - val_loss: 0.0020 - val_acc: 0.7150\n",
      "Epoch 70/100\n",
      "1712/1712 [==============================] - 21s 12ms/step - loss: 0.0021 - acc: 0.7050 - val_loss: 0.0021 - val_acc: 0.7103\n",
      "Epoch 71/100\n",
      "1712/1712 [==============================] - 22s 13ms/step - loss: 0.0021 - acc: 0.7167 - val_loss: 0.0020 - val_acc: 0.7103\n",
      "Epoch 72/100\n",
      "1712/1712 [==============================] - 20s 12ms/step - loss: 0.0020 - acc: 0.7167 - val_loss: 0.0020 - val_acc: 0.7033\n",
      "Epoch 73/100\n",
      "1712/1712 [==============================] - 21s 12ms/step - loss: 0.0020 - acc: 0.7114 - val_loss: 0.0020 - val_acc: 0.7079\n",
      "Epoch 74/100\n",
      "1712/1712 [==============================] - 21s 12ms/step - loss: 0.0019 - acc: 0.7103 - val_loss: 0.0021 - val_acc: 0.6986\n",
      "Epoch 75/100\n",
      "1712/1712 [==============================] - 20s 12ms/step - loss: 0.0019 - acc: 0.7161 - val_loss: 0.0019 - val_acc: 0.6986\n",
      "Epoch 76/100\n",
      "1712/1712 [==============================] - 20s 12ms/step - loss: 0.0019 - acc: 0.7161 - val_loss: 0.0018 - val_acc: 0.6939\n",
      "Epoch 77/100\n",
      "1712/1712 [==============================] - 18s 10ms/step - loss: 0.0019 - acc: 0.7185 - val_loss: 0.0018 - val_acc: 0.7079\n",
      "Epoch 78/100\n",
      "1712/1712 [==============================] - 18s 10ms/step - loss: 0.0018 - acc: 0.7220 - val_loss: 0.0017 - val_acc: 0.7079\n",
      "Epoch 79/100\n",
      "1712/1712 [==============================] - 18s 11ms/step - loss: 0.0018 - acc: 0.7155 - val_loss: 0.0018 - val_acc: 0.7103\n",
      "Epoch 80/100\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 0.0017 - acc: 0.7278 - val_loss: 0.0018 - val_acc: 0.7033\n",
      "Epoch 81/100\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 0.0017 - acc: 0.7190 - val_loss: 0.0018 - val_acc: 0.6963\n",
      "Epoch 82/100\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 0.0017 - acc: 0.7220 - val_loss: 0.0017 - val_acc: 0.6916\n",
      "Epoch 83/100\n",
      "1712/1712 [==============================] - 20s 12ms/step - loss: 0.0017 - acc: 0.7278 - val_loss: 0.0017 - val_acc: 0.7009\n",
      "Epoch 84/100\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 0.0017 - acc: 0.7208 - val_loss: 0.0017 - val_acc: 0.6893\n",
      "Epoch 85/100\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 0.0016 - acc: 0.7371 - val_loss: 0.0017 - val_acc: 0.6986\n",
      "Epoch 86/100\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 0.0016 - acc: 0.7272 - val_loss: 0.0016 - val_acc: 0.6939\n",
      "Epoch 87/100\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 0.0016 - acc: 0.7161 - val_loss: 0.0018 - val_acc: 0.7009\n",
      "Epoch 88/100\n",
      "1712/1712 [==============================] - 22s 13ms/step - loss: 0.0016 - acc: 0.7301 - val_loss: 0.0016 - val_acc: 0.7056\n",
      "Epoch 89/100\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 0.0016 - acc: 0.7336 - val_loss: 0.0017 - val_acc: 0.7126\n",
      "Epoch 90/100\n",
      "1712/1712 [==============================] - 20s 12ms/step - loss: 0.0016 - acc: 0.7272 - val_loss: 0.0016 - val_acc: 0.7150\n",
      "Epoch 91/100\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 0.0016 - acc: 0.7366 - val_loss: 0.0015 - val_acc: 0.7150\n",
      "Epoch 92/100\n",
      "1712/1712 [==============================] - 18s 11ms/step - loss: 0.0015 - acc: 0.7336 - val_loss: 0.0015 - val_acc: 0.7196\n",
      "Epoch 93/100\n",
      "1712/1712 [==============================] - 20s 12ms/step - loss: 0.0015 - acc: 0.7290 - val_loss: 0.0016 - val_acc: 0.7126\n",
      "Epoch 94/100\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 0.0015 - acc: 0.7395 - val_loss: 0.0015 - val_acc: 0.7266\n",
      "Epoch 95/100\n",
      "1712/1712 [==============================] - 22s 13ms/step - loss: 0.0015 - acc: 0.7395 - val_loss: 0.0016 - val_acc: 0.7290\n",
      "Epoch 96/100\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 0.0015 - acc: 0.7278 - val_loss: 0.0015 - val_acc: 0.7173\n",
      "Epoch 97/100\n",
      "1712/1712 [==============================] - 20s 12ms/step - loss: 0.0014 - acc: 0.7465 - val_loss: 0.0015 - val_acc: 0.7196\n",
      "Epoch 98/100\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 0.0014 - acc: 0.7366 - val_loss: 0.0014 - val_acc: 0.7126\n",
      "Epoch 99/100\n",
      "1712/1712 [==============================] - 18s 11ms/step - loss: 0.0014 - acc: 0.7442 - val_loss: 0.0015 - val_acc: 0.7033\n",
      "Epoch 100/100\n",
      "1712/1712 [==============================] - 19s 11ms/step - loss: 0.0014 - acc: 0.7383 - val_loss: 0.0014 - val_acc: 0.7103\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n# You can skip all the steps above (from 'Setting the CNN architecture') after running the script for the first time.\\n# Just load the recent model using load_my_CNN_model and use it to predict keypoints on any face data\\nmy_model = load_my_CNN_model('my_model')\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from utils import load_data\n",
    "#from my_CNN_model import *\n",
    "import cv2\n",
    "\n",
    "\n",
    "# Load training set\n",
    "X_train, y_train = load_data()\n",
    "\n",
    "# NOTE: Please check the load_data() method in utils.py to see how the data is preprocessed (normalizations and stuff)\n",
    "\n",
    "# Setting the CNN architecture\n",
    "my_model = get_my_CNN_model_architecture()\n",
    "\n",
    "# Compiling the CNN model with an appropriate optimizer and loss and metrics\n",
    "compile_my_CNN_model(my_model, optimizer = 'adam', loss = 'mean_squared_error', metrics = ['accuracy'])\n",
    "\n",
    "# Training the model\n",
    "hist = train_my_CNN_model(my_model, X_train, y_train)\n",
    "\n",
    "# train_my_CNN_model returns a History object. History.history attribute is a record of training loss values and metrics\n",
    "# values at successive epochs, as well as validation loss values and validation metrics values (if applicable).\n",
    "\n",
    "# Saving the model\n",
    "save_my_CNN_model(my_model, 'my_model')\n",
    "\n",
    "'''\n",
    "# You can skip all the steps above (from 'Setting the CNN architecture') after running the script for the first time.\n",
    "# Just load the recent model using load_my_CNN_model and use it to predict keypoints on any face data\n",
    "my_model = load_my_CNN_model('my_model')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import load_model\n",
    "from pandas.io.parsers import read_csv\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "def load_data(test=False):\n",
    "    \"\"\"\n",
    "    Loads data from FTEST if *test* is True, otherwise from FTRAIN.\n",
    "    Important that the files are in a `data` directory\n",
    "    \"\"\"\n",
    "    FTRAIN = 'E:\\\\Project\\\\training.csv'\n",
    "    FTEST = 'E:\\\\Project\\\\test.csv'\n",
    "    fname = FTEST if test else FTRAIN\n",
    "    df = read_csv(os.path.expanduser(fname))  # load dataframes\n",
    "\n",
    "    # The Image column has pixel values separated by space; convert\n",
    "    # the values to numpy arrays:\n",
    "    df['Image'] = df['Image'].apply(lambda im: np.fromstring(im, sep=' '))\n",
    "\n",
    "    df = df.dropna()  # drop all rows that have missing values in them\n",
    "\n",
    "    X = np.vstack(df['Image'].values) / 255.  # scale pixel values to [0, 1] (Normalizing)\n",
    "    X = X.astype(np.float32)\n",
    "    X = X.reshape(-1, 96, 96, 1) # return each images as 96 x 96 x 1\n",
    "\n",
    "    if not test:  # only FTRAIN has target columns\n",
    "        y = df[df.columns[:-1]].values\n",
    "        y = (y - 48) / 48  # scale target coordinates to [-1, 1] (Normalizing)\n",
    "        X, y = shuffle(X, y, random_state=42)  # shuffle train data\n",
    "        y = y.astype(np.float32)\n",
    "    else:\n",
    "        y = None\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the model built in the previous step\n",
    "my_model = load_my_CNN_model('my_model')\n",
    "\n",
    "# Face cascade to detect faces\n",
    "face_cascade = cv2.CascadeClassifier('E:\\\\Project\\\\haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Define the upper and lower boundaries for a color to be considered \"Blue\"\n",
    "blueLower = np.array([100, 60, 60])\n",
    "blueUpper = np.array([140, 255, 255])\n",
    "\n",
    "# Define a 5x5 kernel for erosion and dilation\n",
    "kernel = np.ones((5, 5), np.uint8)\n",
    "\n",
    "# Define filters\n",
    "filters = ['E:\\\\Project\\\\sunglasses.png', 'E:\\\\Project\\\\sunglasses_2.png', 'E:\\\\Project\\\\sunglasses_3.jpg', 'E:\\\\Project\\\\sunglasses_4.png', 'E:\\\\Project\\\\sunglasses_5.jpg', 'E:\\\\Project\\\\sunglasses_6.png']\n",
    "filterIndex = 0\n",
    "\n",
    "# Load the video - O for webcam input\n",
    "camera = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    \n",
    "    (grabbed, frame) = camera.read()\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    frame2 = np.copy(frame)\n",
    "    \n",
    "    # Convert to HSV and GRAY for convenience\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces using the haar cascade object\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.25, 6)\n",
    "    \n",
    "     # Add the 'Next Filter' button to the frame\n",
    "    frame = cv2.rectangle(frame, (500,10), (620,65), (235,50,50), -1)\n",
    "    cv2.putText(frame, \"NEXT FILTER\", (512, 37), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "    # Determine which pixels fall within the blue boundaries \n",
    "    # and then blur the binary image to remove noise\n",
    "    blueMask = cv2.inRange(hsv, blueLower, blueUpper)\n",
    "    blueMask = cv2.erode(blueMask, kernel, iterations=2)\n",
    "    blueMask = cv2.morphologyEx(blueMask, cv2.MORPH_OPEN, kernel)\n",
    "    blueMask = cv2.dilate(blueMask, kernel, iterations=1)\n",
    "    \n",
    "    # Find contours (bottle cap in my case) in the image\n",
    "    (_, cnts, _) = cv2.findContours(blueMask.copy(), cv2.RETR_EXTERNAL,\n",
    "    \tcv2.CHAIN_APPROX_SIMPLE)\n",
    "    center = None\n",
    "\n",
    "    # Check to see if any contours were found\n",
    "    if len(cnts) > 0:\n",
    "    \t# Sort the contours and find the largest one -- we\n",
    "    \t# will assume this contour correspondes to the area of the bottle cap\n",
    "        cnt = sorted(cnts, key = cv2.contourArea, reverse = True)[0]\n",
    "        # Get the radius of the enclosing circle around the found contour\n",
    "        ((x, y), radius) = cv2.minEnclosingCircle(cnt)\n",
    "        # Draw the circle around the contour\n",
    "        cv2.circle(frame, (int(x), int(y)), int(radius), (0, 255, 255), 2)\n",
    "        # Get the moments to calculate the center of the contour (in this case Circle)\n",
    "        M = cv2.moments(cnt)\n",
    "        center = (int(M['m10'] / M['m00']), int(M['m01'] / M['m00']))\n",
    "        \n",
    "        # Once \n",
    "        if center[1] <= 65:\n",
    "            if 500 <= center[0] <= 620: # Next Filter\n",
    "                filterIndex += 1\n",
    "                filterIndex %= 6\n",
    "                continue\n",
    "\n",
    "                \n",
    "       # Loop over all the faces found in the frame\n",
    "    for (x, y, w, h) in faces:\n",
    "        # Make the faces ready for the model (normalize, resize and stuff)\n",
    "        gray_face = gray[y:y+h, x:x+w]\n",
    "        color_face = frame[y:y+h, x:x+w]\n",
    "\n",
    "        # Normalize to match the input format of the model - Range of pixel to [0, 1]\n",
    "        gray_normalized = gray_face / 255\n",
    "\n",
    "        # Resize it to 96x96 to match the input format of the model\n",
    "        original_shape = gray_face.shape # A Copy for future reference\n",
    "        face_resized = cv2.resize(gray_normalized, (96, 96), interpolation = cv2.INTER_AREA)\n",
    "        face_resized_copy = face_resized.copy()\n",
    "        face_resized = face_resized.reshape(1, 96, 96, 1)\n",
    "\n",
    "        # Predict the keypoints using the model\n",
    "        keypoints = my_model.predict(face_resized)\n",
    "\n",
    "        # De-Normalize the keypoints values\n",
    "        keypoints = keypoints * 48 + 48\n",
    "\n",
    "        # Map the Keypoints back to the original image\n",
    "        face_resized_color = cv2.resize(color_face, (96, 96), interpolation = cv2.INTER_AREA)\n",
    "        face_resized_color2 = np.copy(face_resized_color)\n",
    "\n",
    "        # Pair the keypoints together - (x1, y1)\n",
    "        points = []\n",
    "        for i, co in enumerate(keypoints[0][0::2]):\n",
    "            points.append((co, keypoints[0][1::2][i]))\n",
    "              # Add FILTER to the frame\n",
    "        \n",
    "        sunglasses = cv2.imread(filters[filterIndex], cv2.IMREAD_UNCHANGED)\n",
    "        sunglass_width = int((points[7][0]-points[9][0])*1.1)\n",
    "        sunglass_height = int((points[10][1]-points[8][1])/1.1)\n",
    "        sunglass_resized = cv2.resize(sunglasses, (sunglass_width, sunglass_height), interpolation = cv2.INTER_CUBIC)\n",
    "        transparent_region = sunglass_resized[:,:,:3] != 0\n",
    "        face_resized_color[int(points[9][1]):int(points[9][1])+sunglass_height, int(points[9][0]):int(points[9][0])+sunglass_width,:][transparent_region] = sunglass_resized[:,:,:3][transparent_region]\n",
    "\n",
    "        # Map the face with shades back to its original shape\n",
    "        frame[y:y+h, x:x+w] = cv2.resize(face_resized_color, original_shape, interpolation = cv2.INTER_CUBIC)\n",
    "\n",
    "        # Add KEYPOINTS to the frame2\n",
    "        for keypoint in points:\n",
    "            cv2.circle(face_resized_color2, keypoint, 1, (0,255,0), 1)\n",
    "        \n",
    "        # Map the face with keypoints back to the original image (a separate one)\n",
    "        frame2[y:y+h, x:x+w] = cv2.resize(face_resized_color2, original_shape, interpolation = cv2.INTER_CUBIC)\n",
    " # Show the frame and the frame2\n",
    "        cv2.imshow(\"Selfie Filters\", frame)\n",
    "        cv2.imshow(\"Facial Keypoints\", frame2)\n",
    "\n",
    "    # If the 'q' key is pressed, stop the loop\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "# Cleanup the camera and close any open windows\n",
    "camera.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
